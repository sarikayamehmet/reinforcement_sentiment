{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import MRLoader\n",
    "batch_size = 64\n",
    "\n",
    "loader = MRLoader(batch_size)\n",
    "train_loader, test_loader = loader.get_dataset()\n",
    "tokenizer = loader.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import Glove\n",
    "glove = Glove(300)\n",
    "vocab_size, embedding_dim = glove.vocab_size, glove.embedding_dim\n",
    "embedding_matrix = glove.get_embedding(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size, output_dim=1, num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.input_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.input_dim)\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            self.input_dim, \n",
    "            self.hidden_dim, \n",
    "            self.num_layers, \n",
    "            bidirectional=True,\n",
    "            batch_first=True, \n",
    "            dropout=0.5\n",
    "        )\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim * 2, output_dim)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers * 2, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers * 2, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    def set_embedding_weights(self, embedding_matrix):\n",
    "        self.embedding.weight = nn.Parameter(embedding_matrix)\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both \n",
    "        # have shape (num_layers, batch_size, hidden_dim).\n",
    "        X_embedded = self.embedding(inp.long())\n",
    "        \n",
    "        sa, sb, sc = X_embedded.shape\n",
    "        ha, hb = self.hidden\n",
    "        if sa < self.batch_size:\n",
    "            X_embedded = torch.cat([X_embedded, torch.zeros(self.batch_size-sa, sb, sc)])\n",
    "\n",
    "        lstm_out, self.hidden = self.lstm(X_embedded, (ha, hb))\n",
    "\n",
    "        # Only take the output from the final timetep\n",
    "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "        y_pred = self.linear(torch.cat([self.hidden[0][0], self.hidden[0][1]], axis=1))\n",
    "\n",
    "        y_pred = F.sigmoid(y_pred)\n",
    "        return y_pred.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(\n",
    "        vocab_size=vocab_size,\n",
    "        embedding_dim=embedding_dim, \n",
    "        hidden_dim=168, \n",
    "        batch_size=batch_size, \n",
    "        output_dim=1, \n",
    "        num_layers=1\n",
    ")\n",
    "model.set_embedding_weights(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "optimiser = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "\n",
    "hist = np.zeros(num_epochs*len(train_loader))\n",
    "j = 0\n",
    "for e in range(num_epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        # Clear stored gradient\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Initialise hidden state\n",
    "        # Don't do this if you want your LSTM to be stateful\n",
    "        model.hidden = model.init_hidden()\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = model(x.long())\n",
    "        if len(x) < model.batch_size:\n",
    "            y_pred = y_pred[:len(x)]\n",
    "        \n",
    "        loss = loss_fn(y_pred.view(-1, 1), y.view(-1, 1))\n",
    "        hist[j] = loss.item()\n",
    "\n",
    "        # Zero out gradient, else they will accumulate between epochs\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_num = 0\n",
    "correct_num = 0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        # Forward pass\n",
    "        y_pred = model(x.long())\n",
    "        if len(y) < model.batch_size:\n",
    "            y_pred = y_pred[:len(y)]\n",
    "            \n",
    "        full_num += len(y)\n",
    "        correct_num += (y_pred.reshape(-1, 1).round() == y).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.782"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_num / full_num"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
